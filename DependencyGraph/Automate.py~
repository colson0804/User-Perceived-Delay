import datetime
import subprocess
import shlex
import sys
from selenium import webdriver
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys
from urlparse import urlparse
import time
import requests
import logging
import sys
import json
import os
import subprocess
import psutil
import argparse
import time
import threading


def automate_driver(file_name):
    driver = shlex.split("python firefox-driver.py -f proxyvisit -fu http://www.cnn.com -t 15 -c air_configure -p CNN")
    if subprocess.call(driver) != 0:
    	sys.exit()
    
    commonurl = shlex.split("python LogAnalysis.py -f getcommonurl -d logs -p CNN -ho cnnHost")
    subprocess.call(commonurl)

    graph = shlex.split("python LogAnalysis.py -f generategraph -p WSJ -d ./logs/ -fu http://www.cnn.com/ -go cnnGraph -lus finals.txt -c cnnHost")
    subprocess.call(graph)

def automate_analyze(host_name, graph_name, last_url, bandwidth, trial_num):
    # setting up bandwidth...
    bandwidth_in_bits = bandwidth * 8
    dnctl = shlex.split("sudo wondershaper -a eth0 -d %d -u 5120" % bandwidth)
    subprocess.call(dnctl)
    #dummynet = shlex.split("echo \"dummynet in all pipe 1\" >> /etc/pf.conf")
    #subprocess.call(dummynet)


    # collecting data...
    url = "http://www.cnn.com/"
             
    #profile = webdriver.FirefoxProfile("/home/yanghu/.mozilla/firefox/cv0k6zw7.default")
    profile = webdriver.FirefoxProfile("/home/ubuntu/.mozilla/firefox/8ld7gd0a.withoutProxy")
    f = open("broscript/test.txt", "w")
    listen = shlex.split("sudo /usr/local/bro/bin/bro -i eth0 -C broscript/httpinfo.bro")
    browser = webdriver.Firefox(profile)
    background = subprocess.Popen(listen, stdout = f)

    openNewTab(browser)
    browser.get(url)
    #thread = threading.Thread(browser.get(url))
    #thread.start()
    #thread.join(15)
    #if thread.is_alive():
    #    print "open url time out!"
    #    background.terminate()
    #    thread.join()

    time.sleep(1)
    try:
        background.terminate()
    except:
        print "cannot terminate bro"
        browser.quit()
        f.close()
        automate_analyze(host_name, graph_name, last_url, bandwidth, trial_num)
        return
    f.close()
    try:
        closeCurrentTab(browser)
    except:
        print "cannot close current tab"
        browser.quit()
        automate_analyze(host_name, graph_name, last_url, bandwidth, trial_num)
        return
    browser.quit()   
    output = open("diffbd%d/%dtest.txt" % (trial_num, bandwidth), "w")
    analyze = shlex.split("python LogAnalysis.py -f analyzebrolog -fu http://www.cnn.com/ -lus " + last_url + " -gi " + graph_name + " -c " + host_name + " -b broscript/test.txt")
    #try:
    subprocess.call(analyze, stderr = output)
    #except:
    #    print "an error just happened"
    #	remove_bad_file = shlex.split("rm -f %dequalbd/%dtest.txt" % (trial_num, bandwidth))
    #    subprocess.call(remove_bad_file)
    #	automate_analyze(host_name, graph_name, last_url, bandwidth, trial_num)
    #    return     
    
    output.close()
        
    output = open("diffbd%d/%dtest.txt" % (trial_num, bandwidth), "r")
    output_string = output.read()
    if len(output_string) < 10:
        print "Output File is empty"
        output.close()
    	automate_analyze(host_name, graph_name, last_url, bandwidth, trial_num)
        return

    output.close()
    clearm = shlex.split("sudo wondershaper -c -a eth0")
    subprocess.call(clearm)


"""
    nf = open("%dkb_output.txt" % bandwidth, "r")
    rtt = nf.readline()
    size = nf.readline()
    obj = nf.readline()
    lat = nf.readline()
    lat0 = lat[10:len(lat)-2]
    nf.readline()
    nf.readline()
    nf.readline()
    lat = nf.readline()
    lat1 = lat[10:len(lat)-2]
    nf.readline()
    nf.readline()
    nf.readline()
    lat = nf.readline()
    lat2 = lat[10:len(lat)-2]
    print lat0
    print lat1
    print lat2
    avg = float(lat0) + float(lat1) + float(lat2)
    avg = avg / 3.0
    nf.close()
    nf = open("%dkb_output.txt" % bandwidth, "w")
    nf.write(rtt)
    nf.write(size)
    nf.write(obj)
    nf.write("\"latency\":%d}\n" %avg)
    nf.close()
"""
def openNewTab(browser):
	if sys.platform == "darwin":
		ActionChains(browser).send_keys(Keys.COMMAND, "t").perform()
		ActionChains(browser).send_keys(Keys.COMMAND, "t").perform()
	elif sys.platform == "linux2":
		ActionChains(browser).send_keys(Keys.CONTROL, "t").perform()
		ActionChains(browser).send_keys(Keys.CONTROL, "t").perform()
	else:
		logger.error("openNewTab unsupported OS: %s"%sys.platform)

def closeCurrentTab(browser):
	if sys.platform == "darwin":
		browser.find_element_by_tag_name('body').send_keys(Keys.COMMAND + 'w')
	elif sys.platform == "linux2":
		browser.find_element_by_tag_name('body').send_keys(Keys.CONTROL + 'w')
	else:
		logger.error("closeCurrentTab unsupported OS: %s"%sys.platform)
    

if __name__ == '__main__':
    #file_name = sys.argv[1]
    host_name = sys.argv[1]
    graph_name = sys.argv[2]
    #last_urls = "http://www.ugdturner.com/xd.sjs"
    last_urls = "finals.txt" 
    #automate_driver("test")

    
    #bandwidth = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]
    bandwidth = range(64000, 800, - 800)
    num_trials = 5
    for i in bandwidth:
        rtt = []
        avg_rtt = []
        for k in range(0, 200):
            rtt.append(0)
            avg_rtt.append(0)
        latency = 0
        j = 0
        skip = False
        while j < num_trials:
            skip = False
            j = j + 1
            print j
            automate_analyze(host_name, graph_name, last_urls, i, j)
            f = open("diffbd%d/%dtest.txt" % (j, i), "r")
            x = json.load(f)
            num_rtt_data = len(x['files'])
            single_latency = 0
            for k in range(0, num_rtt_data):
                if x['files'][k]["latency"] < 0.15 or x['files'][k]["rtt"] < 0.00001 or x['files'][k]["latency"] > 20:
                    print "problem with data range"
                    j = j - 1
                    skip = True
                    break
                if x['files'][k]['latency'] > single_latency:
                    single_latency = x['files'][k]['latency']
                rtt[k] += x['files'][k]["rtt"]
            print "single latency: %d" % single_latency
            print "aggregate latency: %d" % latency
            if skip: 
                f.close()
                continue
            latency += single_latency
            f.close()

        avg_latency = latency / num_trials
        data_dictionary = {"latency":avg_latency, "time":datetime.datetime.now().hour}
        for k in range(0, num_rtt_data):
            avg_rtt[k] = rtt[k] / num_trials
            index = 'avg_rtt%d' % k
            data_dictionary[index] = avg_rtt[k]
        avg_file = open('diffbd/%dtest.txt' % i, 'w')
        json.dump(data_dictionary, avg_file)
        avg_file.close()

